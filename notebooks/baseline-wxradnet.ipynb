{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d85fc7-f61d-4118-a0bf-8f609cc8e29f",
   "metadata": {},
   "source": [
    "# Baseline Models for WxRADNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b24a9fbb-32cf-41e2-b5b5-fdcbf0ba1e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import optuna\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import seaborn as sns\n",
    "plt.style.use(\"https://drive.google.com/uc?id=1NKA45YUOjoDwewGrI88Nx_hrqtBv5kuI&export=download\")\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = \"../parser/data/\"\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "INPUT_SIZE = 65536\n",
    "OUTPUT_SIZE = 65536\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd1bd841-ef65-4559-ade4-199531f5212a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878a9a75-a5e5-4e2e-ad75-5b251cbb72b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_rmse(test_targets, test_predictions):\n",
    "    # Reshape to (batch_size * sequence_length, features)\n",
    "    test_targets_flat = test_targets.reshape(-1, test_targets.shape[-1])\n",
    "    test_predictions_flat = test_predictions.reshape(-1, test_predictions.shape[-1])\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test_targets_flat, test_predictions_flat))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05630115-0869-43b0-9aaf-92573df7745f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ThunderstormDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "        self.dataset_sizes = [np.load(file_path, mmap_mode=\"r\").shape[0] for file_path in file_paths]\n",
    "        self.cumulative_sizes = np.cumsum(self.dataset_sizes)\n",
    "        self.total_size = self.cumulative_sizes[-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Find which file this idx belongs to\n",
    "        file_idx = np.searchsorted(self.cumulative_sizes, idx, side='right')\n",
    "        if file_idx == 0:\n",
    "            within_file_idx = idx\n",
    "        else:\n",
    "            within_file_idx = idx - self.cumulative_sizes[file_idx - 1]\n",
    "        \n",
    "        file_path = self.file_paths[file_idx]\n",
    "        data = np.load(file_path, mmap_mode='r')\n",
    "        item = data[within_file_idx]\n",
    "        \n",
    "        # Split the item into inputs and targets\n",
    "        inputs = item[:6].reshape(-1)  # Flatten the first 6 images\n",
    "        targets = item[6:].reshape(-1)  # Flatten the last 6 images\n",
    "        \n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66acf63c-45ff-4238-8df6-ab46fd7957e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_file_paths = [PATH + file for file in sorted(os.listdir(PATH))][0:29]\n",
    "valid_file_paths = [PATH + file for file in sorted(os.listdir(PATH))][29:38]\n",
    "test_file_paths = [PATH + file for file in sorted(os.listdir(PATH))][38:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6c49bab-2369-4df3-929c-b6c569b2d2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ThunderstormDataset(train_file_paths)\n",
    "valid_dataset = ThunderstormDataset(valid_file_paths)\n",
    "test_dataset = ThunderstormDataset(test_file_paths)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238a10b-92e7-456d-8ef5-4551749d1bac",
   "metadata": {},
   "source": [
    "## 1. Constant Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98643da8-9dc3-4785-84a4-9bf4adbd7129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def baseline_model(test_loader, device):\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Reshape to (batch_size, 6, 256*256) before applying the baseline prediction\n",
    "        inputs = inputs.view(inputs.size(0), 6, 256*256)\n",
    "        targets = targets.view(targets.size(0), 6, 256*256)\n",
    "        \n",
    "        # Predict the last seen image\n",
    "        baseline_pred = inputs[:, -1, :].unsqueeze(1).repeat(1, 6, 1)\n",
    "        \n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "        all_predictions.append(baseline_pred.cpu().numpy())\n",
    "\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    rmse = compute_rmse(all_targets, all_predictions)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d294a580-dff6-4932-92ff-152a5a185972",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m baseline_rmse \u001b[38;5;241m=\u001b[39m baseline_model(test_loader, device)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 20\u001b[0m, in \u001b[0;36mbaseline_model\u001b[0;34m(test_loader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_targets, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m rmse \u001b[38;5;241m=\u001b[39m compute_rmse(all_targets, all_predictions)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rmse\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mcompute_rmse\u001b[0;34m(test_targets, test_predictions)\u001b[0m\n\u001b[1;32m      4\u001b[0m test_predictions_flat \u001b[38;5;241m=\u001b[39m test_predictions\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, test_predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Compute RMSE\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(test_targets_flat, test_predictions_flat))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rmse\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:510\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    507\u001b[0m     y_true, y_pred, multioutput\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m--> 510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:393\u001b[0m, in \u001b[0;36m_average_dispatcher\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_average_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, returned\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    394\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, weights)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_average_dispatcher)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maverage\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, returned\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    400\u001b[0m             keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baseline_rmse = baseline_model(test_loader, device)\n",
    "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea47b6c7-9f72-4124-be44-13e7f10050a8",
   "metadata": {},
   "source": [
    "## 2. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72b49667-6838-4272-819e-5d1db6425f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.load('../thunderstorm_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77a57c8f-5230-4136-929f-c75158c831e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34240, 12, 256, 256, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88f5752c-d8df-439f-9829-d375e70dab67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for sequence in data:\n",
    "    inputs = sequence[:6].reshape(-1)\n",
    "    targets = sequence[6:].reshape(-1)\n",
    "    X.append(inputs)\n",
    "    y.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56a5255c-f4c1-4794-a629-67f222816c28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34240, 393216)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937e24f-1972-4873-9846-d77ba6b89121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array(y).reshape(-1, 6 * 65536)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68068df1-285a-4d30-b497-b90df476f7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97a3ff-90a3-4880-95f5-0f14eed41377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53744d9-29e1-4cba-9cef-c1f6385fcc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1560a1eb-4d9d-4eeb-8ba8-c66b7dc2c7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGBMDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        self.file_paths = file_paths\n",
    "        self.dataset_sizes = [np.load(file_path, mmap_mode='r').shape[0] for file_path in file_paths]\n",
    "        self.cumulative_sizes = np.cumsum(self.dataset_sizes)\n",
    "        self.total_size = self.cumulative_sizes[-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_idx = np.searchsorted(self.cumulative_sizes, idx, side='right')\n",
    "        if file_idx == 0:\n",
    "            within_file_idx = idx\n",
    "        else:\n",
    "            within_file_idx = idx - self.cumulative_sizes[file_idx - 1]\n",
    "        \n",
    "        file_path = self.file_paths[file_idx]\n",
    "        data = np.load(file_path, mmap_mode='r')\n",
    "        item = data[within_file_idx]\n",
    "        \n",
    "        inputs = item[:6].reshape(-1)  # Flatten the first 6 images\n",
    "        targets = item[6:].reshape(-1)  # Flatten the last 6 images\n",
    "        \n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b8921ff-8e2e-4dd7-848a-00c49aaaa6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_targets(dataset):\n",
    "    data, targets = [], []\n",
    "    for inputs, outputs in dataset:\n",
    "        data.append(inputs)\n",
    "        targets.append(outputs)\n",
    "        \n",
    "    data = np.array(data)\n",
    "    targets = np.array(targets).reshape(-1, 6 * 65536)\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71202ad9-abf9-431d-87d6-c4898bfec873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = LightGBMDataset(train_file_paths)\n",
    "valid_dataset = LightGBMDataset(valid_file_paths)\n",
    "test_dataset = LightGBMDataset(test_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2fb0dec-b167-4b9a-82d8-09b6d0cca610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data, train_targets \u001b[38;5;241m=\u001b[39m get_data_targets(train_dataset)\n\u001b[1;32m      2\u001b[0m valid_data, valid_targets \u001b[38;5;241m=\u001b[39m get_data_targets(valid_dataset)\n\u001b[1;32m      3\u001b[0m test_data, test_targets \u001b[38;5;241m=\u001b[39m get_data_targets(test_dataset)\n",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m, in \u001b[0;36mget_data_targets\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_targets\u001b[39m(dataset):\n\u001b[1;32m      2\u001b[0m     data, targets \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, outputs \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      4\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(inputs)\n\u001b[1;32m      5\u001b[0m         targets\u001b[38;5;241m.\u001b[39mappend(outputs)\n",
      "Cell \u001b[0;32mIn[41], line 19\u001b[0m, in \u001b[0;36mLightGBMDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m     within_file_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[file_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     18\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_paths[file_idx]\n\u001b[0;32m---> 19\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(file_path, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m item \u001b[38;5;241m=\u001b[39m data[within_file_idx]\n\u001b[1;32m     22\u001b[0m inputs \u001b[38;5;241m=\u001b[39m item[:\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the first 6 images\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:453\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_pickle:\n\u001b[1;32m    452\u001b[0m         max_header_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m64\u001b[39m\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    454\u001b[0m                               max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mread_array(fid, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[1;32m    457\u001b[0m                              pickle_kwargs\u001b[38;5;241m=\u001b[39mpickle_kwargs,\n\u001b[1;32m    458\u001b[0m                              max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/format.py:945\u001b[0m, in \u001b[0;36mopen_memmap\u001b[0;34m(filename, mode, dtype, shape, fortran_order, version, max_header_size)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    943\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 945\u001b[0m marray \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mmemmap(filename, dtype\u001b[38;5;241m=\u001b[39mdtype, shape\u001b[38;5;241m=\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m    946\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m marray\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/core/memmap.py:282\u001b[0m, in \u001b[0;36mmemmap.__new__\u001b[0;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fid, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fid\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# py3 returns int for TemporaryFile().name\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(fid\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# same as memmap copies (e.g. memmap + 1)\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m<frozen posixpath>:404\u001b[0m, in \u001b[0;36mabspath\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 24] Too many open files"
     ]
    }
   ],
   "source": [
    "train_data, train_targets = get_data_targets(train_dataset)\n",
    "valid_data, valid_targets = get_data_targets(valid_dataset)\n",
    "test_data, test_targets = get_data_targets(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd30bf-199a-4bda-a3e5-78eeaffad310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 200),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 200),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    train_data_lgb = lgb.Dataset(train_data, label=train_targets)\n",
    "    valid_data_lgb = lgb.Dataset(valid_data, label=valid_targets, reference=train_data_lgb)\n",
    "\n",
    "    model = lgb.train(params, train_data_lgb, valid_sets=[valid_data_lgb])\n",
    "    y_pred = model.predict(valid_data)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(valid_targets, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ba210-9098-4557-83f4-758b8d5482d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977bfb0-cd92-4d2b-ad14-663ba7281525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
